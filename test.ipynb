{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96a0dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
    "from stable_baselines3.common.vec_env import VecNormalize, DummyVecEnv, VecMonitor\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6305a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stochastic_proc.midprice import BrownianMidprice, HistoricalData, HistoricalMidprice, TrueMidprice\n",
    "from stochastic_proc.arrivals import PoissonArrivals, HawkesArrivals\n",
    "from stochastic_proc.dynamics import LimitOrderDynamics, DOGEUSDTDynamics\n",
    "from envs.trading import TradingEnv\n",
    "from agents.BaseAgent import AvellanedaStoikovAgent\n",
    "from agents.GLFT import GLFTAgent\n",
    "from rewards.RewardFunctions import PnLReward, InventoryQuadraticPenalty, SpreadRegularizer, SumReward\n",
    "from utils.plot_single import run_and_log, plot_single_episode\n",
    "from utils.plot_batch import simulate_batch, plot_batch\n",
    "from utils.plot_lite import plot_trajectory, generate_results_table_and_hist, compare_poisson_vs_hawkes\n",
    "from utils.calibration import hawkes_params, glft_half_spreads\n",
    "from envs.SB3tradingenv import SB3TradingVecEnv\n",
    "from data.feed import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7481bf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dogeusdt_data(filepath: str, sample_interval: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and preprocess DOGEUSDT L2 data\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the CSV file\n",
    "        sample_interval: Take every nth row to reduce data size if needed\n",
    "    \"\"\"\n",
    "    print(f\"Loading DOGEUSDT data from {filepath}...\")\n",
    "    data = pd.read_csv(filepath)\n",
    "    \n",
    "    # Sample data if needed (for large datasets)\n",
    "    if sample_interval > 1:\n",
    "        data = data.iloc[::sample_interval].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Loaded {len(data)} rows of DOGEUSDT data\")\n",
    "    print(f\"Columns: {data.columns.tolist()}\")\n",
    "    \n",
    "    # Calculate basic statistics\n",
    "    if len(data) > 0:\n",
    "        # Calculate mid prices for first few rows to understand data\n",
    "        first_row = data.iloc[0]\n",
    "        best_bid = first_row['bids[0].price']\n",
    "        best_ask = first_row['asks[0].price']\n",
    "        mid_price = (best_bid + best_ask) / 2\n",
    "        spread = best_ask - best_bid\n",
    "        \n",
    "        print(f\"First row - Best Bid: {best_bid}, Best Ask: {best_ask}\")\n",
    "        print(f\"Mid Price: {mid_price:.6f}, Spread: {spread:.6f}\")\n",
    "        \n",
    "        # Estimate tick size from data\n",
    "        tick_size = estimate_tick_size(data)\n",
    "        print(f\"Estimated tick size: {tick_size:.6f}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "def estimate_tick_size(data: pd.DataFrame, sample_size: int = 1000) -> float:\n",
    "    \"\"\"Estimate tick size from the data\"\"\"\n",
    "    prices = []\n",
    "    \n",
    "    # Sample some rows to estimate tick size\n",
    "    sample_indices = np.linspace(0, len(data)-1, min(sample_size, len(data)), dtype=int)\n",
    "    \n",
    "    for idx in sample_indices:\n",
    "        row = data.iloc[idx]\n",
    "        # Add best bid/ask and a few levels\n",
    "        for i in range(5):  # Check first 5 levels\n",
    "            bid_col = f'bids[{i}].price'\n",
    "            ask_col = f'asks[{i}].price'\n",
    "            if bid_col in row:\n",
    "                prices.extend([row[bid_col], row[ask_col]])\n",
    "    \n",
    "    if not prices:\n",
    "        return 0.0001  # Default for DOGEUSDT\n",
    "    \n",
    "    prices = np.array(prices)\n",
    "    unique_prices = np.unique(prices)\n",
    "    diffs = np.diff(np.sort(unique_prices))\n",
    "    \n",
    "    # Most common difference is likely the tick size\n",
    "    if len(diffs) > 0:\n",
    "        tick_size = np.min(diffs[diffs > 0])\n",
    "        return float(tick_size)\n",
    "    else:\n",
    "        return 0.0001\n",
    "\n",
    "# data/utils.py (corrected volatility calculation)\n",
    "def calculate_volatility(data: pd.DataFrame, window: int = 1000) -> float:\n",
    "    \"\"\"Calculate instantaneous volatility (per time step) from mid price returns\"\"\"\n",
    "    mid_prices = []\n",
    "    \n",
    "    # Use a reasonable sample size for efficiency\n",
    "    sample_size = min(len(data), 10000)\n",
    "    for idx in range(sample_size):\n",
    "        row = data.iloc[idx]\n",
    "        best_bid = row['bids[0].price']\n",
    "        best_ask = row['asks[0].price']\n",
    "        mid_prices.append((best_bid + best_ask) / 2)\n",
    "    \n",
    "    mid_prices = np.array(mid_prices)\n",
    "    \n",
    "    # Remove any NaN values\n",
    "    mid_prices = mid_prices[~np.isnan(mid_prices)]\n",
    "    \n",
    "    if len(mid_prices) < 2:\n",
    "        return 0.001  # Reasonable default for DOGEUSDT\n",
    "    \n",
    "    # Calculate log returns (this gives us volatility per time step)\n",
    "    returns = np.diff(np.log(mid_prices))\n",
    "    \n",
    "    # Remove extreme outliers\n",
    "    returns_std = np.std(returns)\n",
    "    returns = returns[np.abs(returns) < 5 * returns_std]\n",
    "    \n",
    "    if len(returns) < 2:\n",
    "        return 0.001\n",
    "    \n",
    "    # Use recent data for volatility estimation\n",
    "    if len(returns) > window:\n",
    "        recent_returns = returns[-window:]\n",
    "    else:\n",
    "        recent_returns = returns\n",
    "    \n",
    "    # This is the instantaneous volatility (per time step)\n",
    "    # For AS model, this should be the standard deviation of returns per time step\n",
    "    instantaneous_volatility = np.std(recent_returns)\n",
    "    \n",
    "    print(f\"Calculated instantaneous volatility (per time step): {instantaneous_volatility:.6f}\")\n",
    "    print(f\"Sample size: {len(recent_returns)} returns\")\n",
    "    print(f\"Mean return: {np.mean(recent_returns):.8f}\")\n",
    "    print(f\"Return std: {instantaneous_volatility:.8f}\")\n",
    "    \n",
    "    return float(instantaneous_volatility)\n",
    "\n",
    "# Add this to debug volatility values\n",
    "def debug_volatility_calculation(data: pd.DataFrame):\n",
    "    \"\"\"Debug function to understand volatility in the data\"\"\"\n",
    "    mid_prices = []\n",
    "    \n",
    "    for idx in range(min(1000, len(data))):\n",
    "        row = data.iloc[idx]\n",
    "        best_bid = row['bids[0].price']\n",
    "        best_ask = row['asks[0].price']\n",
    "        mid_prices.append((best_bid + best_ask) / 2)\n",
    "    \n",
    "    mid_prices = np.array(mid_prices)\n",
    "    returns = np.diff(np.log(mid_prices))\n",
    "    \n",
    "    print(f\"Volatility analysis:\")\n",
    "    print(f\"Number of returns: {len(returns)}\")\n",
    "    print(f\"Return stats: min={returns.min():.8f}, max={returns.max():.8f}, std={returns.std():.8f}\")\n",
    "    print(f\"95% of returns between: {np.percentile(returns, 2.5):.8f} and {np.percentile(returns, 97.5):.8f}\")\n",
    "    \n",
    "    # What does this mean in price terms?\n",
    "    typical_price = np.mean(mid_prices)\n",
    "    typical_volatility = returns.std() * typical_price\n",
    "    print(f\"Typical mid price: {typical_price:.6f}\")\n",
    "    print(f\"Typical price move per step: Â±{typical_volatility:.6f}\")\n",
    "    \n",
    "    return returns.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db0d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dogeusdt_env_single(data_path: str, episode_length: int = 1000, \n",
    "                             quote_size: float = 100.0, fill_method: str = \"cross\"):\n",
    "    \"\"\"Create single trajectory environment with DOGEUSDT data\"\"\"\n",
    "    data = load_dogeusdt_data(data_path)\n",
    "    feed = DOGEUSDTL2Feed(data)\n",
    "    check = debug_volatility_calculation(data)\n",
    "    # Use smaller episode length for testing\n",
    "    actual_length = min(episode_length, len(data) - 1)\n",
    "    \n",
    "    # Calculate parameters from data\n",
    "    volatility = calculate_volatility(data)\n",
    "    tick_size = 0.0001  # DOGEUSDT tick size\n",
    "    \n",
    "    dyn = DOGEUSDTDynamics(\n",
    "        feed=feed,\n",
    "        tick_size=tick_size,\n",
    "        quote_size=quote_size,\n",
    "        max_depth=0.01,  # 1% max depth for DOGEUSDT\n",
    "        num_traj=1,\n",
    "        fill_method=fill_method\n",
    "    )\n",
    "    \n",
    "    env = TradingEnv(\n",
    "        dynamics=dyn,\n",
    "        T=actual_length,  # Total time steps\n",
    "        M=actual_length,   # Number of steps\n",
    "        return_vectorized=False\n",
    "    )\n",
    "    \n",
    "    # Store volatility for AS agent\n",
    "    env.volatility = volatility\n",
    "    env.tick_size = tick_size\n",
    "    \n",
    "    return env\n",
    "\n",
    "def create_dogeusdt_env_batch(data_path: str, num_traj: int = 64, \n",
    "                            episode_length: int = 1000, quote_size: float = 100.0):\n",
    "    \"\"\"Create batch environment with DOGEUSDT data for RL training\"\"\"\n",
    "    data = load_dogeusdt_data(data_path)\n",
    "    feed = BatchDOGEUSDTFeed(data, num_traj=num_traj, episode_length=episode_length)\n",
    "    \n",
    "    \n",
    "    volatility = calculate_volatility(data)\n",
    "    tick_size = 0.0001\n",
    "    \n",
    "    dyn = DOGEUSDTDynamics(\n",
    "        feed=feed,\n",
    "        tick_size=tick_size,\n",
    "        quote_size=quote_size,\n",
    "        max_depth=0.01,\n",
    "        num_traj=num_traj,\n",
    "        fill_method=\"cross\"\n",
    "    )\n",
    "    \n",
    "    env = TradingEnv(\n",
    "        dynamics=dyn,\n",
    "        T=episode_length,\n",
    "        M=episode_length,\n",
    "        return_vectorized=True\n",
    "    )\n",
    "    \n",
    "    env.volatility = volatility\n",
    "    env.tick_size = tick_size\n",
    "    \n",
    "    return env\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Single trajectory backtest\n",
    "    env = create_dogeusdt_env_single(\"D:/Documents/CLS/thesis/MM_sandbox/binance_book_snapshot_25_2025-01-01_DOGEUSDT.csv\", episode_length=1000)\n",
    "    \n",
    "    # Use AS agent with estimated volatility\n",
    "    agent = AvellanedaStoikovAgent(env, gamma=0.1)\n",
    "    \n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    pnls = []\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.get_action(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        pnls.append(reward)\n",
    "        \n",
    "        if len(pnls) % 100 == 0:\n",
    "            print(f\"Step {len(pnls)}, PnL: {sum(pnls):.4f}\")\n",
    "    \n",
    "    print(f\"Final PnL: {sum(pnls):.4f}\")\n",
    "    \n",
    "    # For RL training\n",
    "    # env = create_dogeusdt_env_batch(\"dogeusdt_l2.csv\", num_traj=64, episode_length=1000)\n",
    "    # vec_env = SB3TradingVecEnv(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f97ca83",
   "metadata": {},
   "source": [
    "# Avellaneda Stoikov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7d0cac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DOGEUSDT data from D:/Documents/CLS/thesis/MM_sandbox/binance_book_snapshot_25_2025-01-01_DOGEUSDT.csv...\n",
      "Loaded 713815 rows of DOGEUSDT data\n",
      "Columns: ['exchange', 'symbol', 'timestamp', 'local_timestamp', 'asks[0].price', 'asks[0].amount', 'bids[0].price', 'bids[0].amount', 'asks[1].price', 'asks[1].amount', 'bids[1].price', 'bids[1].amount', 'asks[2].price', 'asks[2].amount', 'bids[2].price', 'bids[2].amount', 'asks[3].price', 'asks[3].amount', 'bids[3].price', 'bids[3].amount', 'asks[4].price', 'asks[4].amount', 'bids[4].price', 'bids[4].amount', 'asks[5].price', 'asks[5].amount', 'bids[5].price', 'bids[5].amount', 'asks[6].price', 'asks[6].amount', 'bids[6].price', 'bids[6].amount', 'asks[7].price', 'asks[7].amount', 'bids[7].price', 'bids[7].amount', 'asks[8].price', 'asks[8].amount', 'bids[8].price', 'bids[8].amount', 'asks[9].price', 'asks[9].amount', 'bids[9].price', 'bids[9].amount', 'asks[10].price', 'asks[10].amount', 'bids[10].price', 'bids[10].amount', 'asks[11].price', 'asks[11].amount', 'bids[11].price', 'bids[11].amount', 'asks[12].price', 'asks[12].amount', 'bids[12].price', 'bids[12].amount', 'asks[13].price', 'asks[13].amount', 'bids[13].price', 'bids[13].amount', 'asks[14].price', 'asks[14].amount', 'bids[14].price', 'bids[14].amount', 'asks[15].price', 'asks[15].amount', 'bids[15].price', 'bids[15].amount', 'asks[16].price', 'asks[16].amount', 'bids[16].price', 'bids[16].amount', 'asks[17].price', 'asks[17].amount', 'bids[17].price', 'bids[17].amount', 'asks[18].price', 'asks[18].amount', 'bids[18].price', 'bids[18].amount', 'asks[19].price', 'asks[19].amount', 'bids[19].price', 'bids[19].amount', 'asks[20].price', 'asks[20].amount', 'bids[20].price', 'bids[20].amount', 'asks[21].price', 'asks[21].amount', 'bids[21].price', 'bids[21].amount', 'asks[22].price', 'asks[22].amount', 'bids[22].price', 'bids[22].amount', 'asks[23].price', 'asks[23].amount', 'bids[23].price', 'bids[23].amount', 'asks[24].price', 'asks[24].amount', 'bids[24].price', 'bids[24].amount']\n",
      "First row - Best Bid: 0.316, Best Ask: 0.31601\n",
      "Mid Price: 0.316005, Spread: 0.000010\n",
      "Estimated tick size: 0.000010\n",
      "0         0.316005\n",
      "1         0.316005\n",
      "2         0.316005\n",
      "3         0.316005\n",
      "4         0.316005\n",
      "            ...   \n",
      "713810    0.325125\n",
      "713811    0.325125\n",
      "713812    0.325125\n",
      "713813    0.325125\n",
      "713814    0.325125\n",
      "Length: 713815, dtype: float64 713815\n"
     ]
    }
   ],
   "source": [
    "df= load_dogeusdt_data(\"D:/Documents/CLS/thesis/MM_sandbox/binance_book_snapshot_25_2025-01-01_DOGEUSDT.csv\")\n",
    "midprice = (df['asks[0].price'] + df['bids[0].price']) / 2\n",
    "print(midprice, len(midprice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c4e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED, T, s0, sigma, A, k_fill, N = 42, 1.0, 100, 2, 140, 1.5, 1\n",
    "M = len(midprice)\n",
    "dt = T / M\n",
    "\n",
    "# Make sure midprice has at least one element\n",
    "if len(midprice) == 0:\n",
    "    raise ValueError(\"midprice series is empty\")\n",
    "\n",
    "mid = TrueMidprice(midprice, sigma, num_traj=N, dt=dt, T=T, seed=SEED)\n",
    "arr = PoissonArrivals(A, A, num_traj=N, dt=dt, T=T, seed=SEED)\n",
    "dyn = LimitOrderDynamics(mid, arr, fill_k=k_fill, max_depth=20.0)\n",
    "\n",
    "# Single-trajectory plotting (RL-style)\n",
    "env = TradingEnv(dynamics=dyn, T=T, M=M, seed=SEED, return_vectorized=False)\n",
    "agent = AvellanedaStoikovAgent(env, gamma=0.1)\n",
    "plot_trajectory(env, agent, show_reservation=True)\n",
    "\n",
    "# Batch stats & PnL hist (vectorized episode)\n",
    "mid = BrownianMidprice(s0, sigma, num_traj=512, dt=dt, T=T, seed=SEED)\n",
    "arr = PoissonArrivals(A, A, num_traj=512, dt=dt, T=T, seed=SEED)\n",
    "dyn = LimitOrderDynamics(mid, arr, fill_k=k_fill, max_depth=20.0)\n",
    "env_vec = TradingEnv(dynamics=dyn, T=T, M=M, seed=SEED, return_vectorized=True)\n",
    "agent = AvellanedaStoikovAgent(env_vec, gamma=0.1)\n",
    "results, fig, totals = generate_results_table_and_hist(env_vec, agent)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526c83c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED, T, M, s0, sigma, A, k_fill, N = 42, 1.0, 200, 0.316, 2, 140, 1.5, 1\n",
    "dt = T / M\n",
    "mid = BrownianMidprice(s0, sigma, num_traj=N, dt=dt, T=T, seed=SEED)\n",
    "arr = PoissonArrivals(A, A, num_traj=N, dt=dt, T=T, seed=SEED)\n",
    "dyn = LimitOrderDynamics(mid, arr, fill_k=k_fill, max_depth=20.0)\n",
    "\n",
    "# Single-trajectory plotting (RL-style)\n",
    "env = TradingEnv(dynamics=dyn, T=T, M=M, seed=SEED, return_vectorized=False)\n",
    "agent = AvellanedaStoikovAgent(env, gamma=0.1)\n",
    "plot_trajectory(env, agent, show_reservation=True)\n",
    "\n",
    "# Batch stats & PnL hist (vectorized episode)\n",
    "mid = BrownianMidprice(s0, sigma, num_traj=512, dt=dt, T=T, seed=SEED)\n",
    "arr = PoissonArrivals(A, A, num_traj=512, dt=dt, T=T, seed=SEED)\n",
    "dyn = LimitOrderDynamics(mid, arr, fill_k=k_fill, max_depth=20.0)\n",
    "env_vec = TradingEnv(dynamics=dyn, T=T, M=M, seed=SEED, return_vectorized=True)\n",
    "agent = AvellanedaStoikovAgent(env_vec, gamma=0.1)\n",
    "results, fig, totals = generate_results_table_and_hist(env_vec, agent)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca1b43c",
   "metadata": {},
   "source": [
    "AS model using L2 DOGEUSDT order book data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b366dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"D:/Documents/CLS/thesis/MM_sandbox/binance_book_snapshot_25_2025-01-01_DOGEUSDT.csv\")\n",
    "mid_prices = (data['bids[0].price'] + data['asks[0].price']) / 2\n",
    "timestamps = data['timestamp']\n",
    "# Compute dt in seconds\n",
    "dt = np.diff(timestamps).mean() / 1e6  # if timestamps are in microseconds\n",
    "\n",
    "returns = np.diff(np.log(mid_prices))\n",
    "sigma = np.std(returns) / np.sqrt(dt)  # annualized volatility\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_historical_env(data_path: str, lam_bid: float, lam_ask: float, fill_k: float, max_depth: float = 20.0, sigma: float=2.0):\n",
    "    data = pd.read_csv(data_path)\n",
    "    mid_prices = (data['bids[0].price'] + data['asks[0].price']) / 2\n",
    "    timestamps = data['timestamp']\n",
    "    dt = np.diff(timestamps).mean() / 1e6  # in seconds\n",
    "\n",
    "    T = len(mid_prices) * dt\n",
    "    M = len(mid_prices)\n",
    "\n",
    "    mid = HistoricalMidprice(mid_prices, num_traj=1, dt=dt, T=T)\n",
    "    arr = PoissonArrivals(lam_bid, lam_ask, num_traj=1, dt=dt, T=T)\n",
    "    dyn = LimitOrderDynamics(mid, arr, fill_k, max_depth)\n",
    "\n",
    "    env = TradingEnv(dynamics=dyn, T=T, M=M, return_vectorized=False)\n",
    "    return env\n",
    "env = create_historical_env(data_path=\"D:/Documents/CLS/thesis/MM_sandbox/binance_book_snapshot_25_2025-01-01_DOGEUSDT.csv\",\n",
    "                            lam_bid=140, lam_ask=140, fill_k=5, max_depth=20)\n",
    "\n",
    "agent = AvellanedaStoikovAgent(env, gamma=0.1, sigma=sigma)\n",
    "plot_trajectory(env, agent, show_reservation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89385186",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED, T, M, s0, sigma, A, k_fill, N = 42, 1.0, 200, 100.0, 2.0, 140, 5, 1\n",
    "\n",
    "data = pd.read_csv(\"D:/Documents/CLS/thesis/MM_sandbox/binance_book_snapshot_25_2025-01-01_DOGEUSDT.csv\")\n",
    "mid_prices = (data['bids[0].price'] + data['asks[0].price']) / 2\n",
    "timestamps = pd.to_datetime(data['timestamp'])\n",
    "# Compute dt in seconds\n",
    "dt = np.diff(timestamps).mean() / 1e6  # if timestamps are in microseconds\n",
    "\n",
    "# If we want to use the entire data, then:\n",
    "T = len(mid_prices) * dt\n",
    "M = len(mid_prices)\n",
    "\n",
    "mid = HistoricalMidprice(mid_prices, num_traj=1, dt=dt, T=T, sigma=sigma)\n",
    "arr = PoissonArrivals(A, A, num_traj=1, dt=dt, T=T)\n",
    "dyn = LimitOrderDynamics(mid, arr, k_fill, max_depth=20)\n",
    "\n",
    "env = TradingEnv(dynamics=dyn, T=T, M=M, seed=SEED, return_vectorized=False)\n",
    "agent = AvellanedaStoikovAgent(env, gamma=0.1)\n",
    "plot_trajectory(env, agent, show_reservation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef66231",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "T, M = 1.0, 200\n",
    "s0, sigma = 100.0, 2.0\n",
    "A, k_fill = 140.0, 1.5\n",
    "max_depth = 20.0\n",
    "dt = T / M\n",
    "\n",
    "K_TRAIN = 16  # number of parallel envs (8..32 is common)\n",
    "K_EVAL  = 4\n",
    "\n",
    "os.makedirs(\"./ckpt_best\", exist_ok=True)\n",
    "os.makedirs(\"./ckpt\", exist_ok=True)\n",
    "os.makedirs(\"./tb_mm\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6a1bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(seed_off=0):\n",
    "    def _thunk():\n",
    "        mid = BrownianMidprice(s0, sigma, num_traj=1, dt=dt, T=T, seed=SEED + seed_off)\n",
    "        arr = PoissonArrivals(A, A, num_traj=1, dt=dt, T=T, seed=SEED + seed_off)\n",
    "        dyn = LimitOrderDynamics(mid, arr, fill_k=k_fill, max_depth=max_depth)\n",
    "\n",
    "        env = TradingEnv(dynamics=dyn, T=T, M=M, seed=SEED + seed_off, return_vectorized=False)\n",
    "        return env\n",
    "    return _thunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24ea73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "vec_train = DummyVecEnv([make_env(i) for i in range(K_TRAIN)])\n",
    "vec_train = VecMonitor(vec_train)                                  \n",
    "vec_train = VecNormalize(vec_train, norm_obs=True, norm_reward=False, clip_obs=10.0)\n",
    "\n",
    "# eval\n",
    "vec_eval = DummyVecEnv([make_env(10_000 + i) for i in range(K_EVAL)])\n",
    "vec_eval = VecMonitor(vec_eval)                                    \n",
    "vec_eval = VecNormalize(vec_eval, norm_obs=True, norm_reward=False, clip_obs=10.0)\n",
    "vec_eval.obs_rms = vec_train.obs_rms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb55efa",
   "metadata": {},
   "source": [
    "PPO policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99de5fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    vec_train,\n",
    "    n_steps=M,                               \n",
    "    batch_size=min(4096, K_TRAIN * M),       \n",
    "    learning_rate=3e-4,\n",
    "    n_epochs=10,\n",
    "    gamma=1.0,                              \n",
    "    gae_lambda=0.95,\n",
    "    clip_range=0.2,\n",
    "    vf_coef=0.5,\n",
    "    ent_coef=0.0,\n",
    "    seed=SEED,\n",
    "    policy_kwargs=dict(net_arch=[128, 128]),\n",
    "    tensorboard_log=\"./tb_mm/\",\n",
    "    device=\"auto\",\n",
    ")\n",
    "\n",
    "eval_cb = EvalCallback(\n",
    "    vec_eval,\n",
    "    best_model_save_path=\"./ckpt_best/\",\n",
    "    log_path=\"./eval_logs/\",\n",
    "    eval_freq=(10_000 // M) * M,\n",
    "    n_eval_episodes=5,\n",
    "    deterministic=True,\n",
    ")\n",
    "ckpt_cb = CheckpointCallback(save_freq=50_000, save_path=\"./ckpt/\", name_prefix=\"ppo_mm\")\n",
    "\n",
    "total_timesteps = 1_000_000\n",
    "model.learn(total_timesteps=total_timesteps, callback=[eval_cb, ckpt_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99248b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_plot = 123\n",
    "\n",
    "vec_plot = DummyVecEnv([make_env(seed_plot)])\n",
    "vec_plot = VecMonitor(vec_plot)\n",
    "vec_plot = VecNormalize(vec_plot, norm_obs=True, norm_reward=False, clip_obs=10.0)\n",
    "vec_plot.obs_rms = vec_train.obs_rms\n",
    "\n",
    "raw_env = make_env(seed_plot)()\n",
    "obs_norm = vec_plot.reset()     # (1, obs_dim)\n",
    "obs_raw, _ = raw_env.reset(seed=seed_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b46cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming obs layout: [price, inventory, time_idx, cash]\n",
    "ASSET_PRICE, INVENTORY, TIMEIDX, CASH = 0, 1, 2, 3\n",
    "\n",
    "S_pre, S_post = [], []\n",
    "Q, C, T_idx = [], [], []\n",
    "HB, HA = [], []\n",
    "R = []\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    \n",
    "    action, _ = model.predict(obs_norm, deterministic=True)\n",
    "\n",
    "    \n",
    "    obs_norm, r_vec, dones_vec, infos = vec_plot.step(action)\n",
    "    done = bool(dones_vec[0])\n",
    "\n",
    "    \n",
    "    next_obs_raw, r_raw, term_raw, trunc_raw, info_raw = raw_env.step(action[0])\n",
    "\n",
    "    \n",
    "    S_pre.append(obs_raw[ASSET_PRICE])\n",
    "    Q.append(obs_raw[INVENTORY])\n",
    "    T_idx.append(obs_raw[TIMEIDX])\n",
    "    C.append(obs_raw[CASH])\n",
    "    HB.append(action[0, 0])\n",
    "    HA.append(action[0, 1])\n",
    "    R.append(float(r_raw))\n",
    "    S_post.append(next_obs_raw[ASSET_PRICE])\n",
    "\n",
    "    obs_raw = next_obs_raw  \n",
    "\n",
    "S_pre  = np.asarray(S_pre)           \n",
    "S_post = np.asarray(S_post)               \n",
    "Q      = np.asarray(Q)\n",
    "C      = np.asarray(C)\n",
    "T_idx  = np.asarray(T_idx)\n",
    "HB     = np.asarray(HB)\n",
    "HA     = np.asarray(HA)\n",
    "R      = np.asarray(R)\n",
    "\n",
    "timestamps = T_idx * (T / M)\n",
    "cum_R = np.cumsum(R)\n",
    "bid_quoted = S_post - HB\n",
    "ask_quoted = S_post + HA\n",
    "\n",
    "print(f\"Episode PnL: {cum_R[-1]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc95e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 10))\n",
    "ax3b = ax3.twinx()\n",
    "\n",
    "# (1) Cumulative PnL\n",
    "ax1.plot(timestamps, cum_R, lw=1.8)\n",
    "ax1.set_title(\"Cumulative Reward (PnL)\")\n",
    "ax1.set_xlabel(\"time\"); ax1.set_ylabel(\"PnL\"); ax1.grid(alpha=0.3)\n",
    "\n",
    "# (2) Mid & Quotes\n",
    "ax2.plot(timestamps, S_pre, color=\"k\", lw=1.5, label=\"Mid Price\")\n",
    "ax2.plot(timestamps, bid_quoted, color=\"tab:blue\",  alpha=0.9, label=\"Bid Price\")\n",
    "ax2.plot(timestamps, ask_quoted, color=\"tab:orange\", alpha=0.9, label=\"Ask Price\")\n",
    "ax2.set_title(\"Mid & PPO Quotes\")\n",
    "ax2.set_xlabel(\"time\"); ax2.set_ylabel(\"price\")\n",
    "ax2.grid(alpha=0.3); ax2.legend(loc=\"best\")\n",
    "\n",
    "# (3) Inventory & Cash\n",
    "ax3.plot(timestamps, Q, color=\"tab:red\",   label=\"Inventory\")\n",
    "ax3b.plot(timestamps, C, color=\"tab:green\", label=\"Cash\")\n",
    "ax3.set_title(\"Inventory & Cash\")\n",
    "ax3.set_xlabel(\"time\"); ax3.set_ylabel(\"inventory\"); ax3b.set_ylabel(\"cash\")\n",
    "ax3.grid(alpha=0.3)\n",
    "h1,l1 = ax3.get_legend_handles_labels()\n",
    "h2,l2 = ax3b.get_legend_handles_labels()\n",
    "ax3.legend(h1+h2, l1+l2, loc=\"best\")\n",
    "\n",
    "# (4) Actions (half-spreads)\n",
    "ax4.plot(timestamps, HB, label=\"Bid half-spread\")\n",
    "ax4.plot(timestamps, HA, label=\"Ask half-spread\")\n",
    "ax4.set_title(\"PPO Actions\"); ax4.set_xlabel(\"time\"); ax4.set_ylabel(\"half-spread\")\n",
    "ax4.legend(loc=\"best\"); ax4.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c14ec64",
   "metadata": {},
   "source": [
    "Infinite horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9cd517",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED, T, M, s0, sigma, A, k_fill, N = 42, 1.0, 200, 100.0, 2.0, 140.0, 1.5, 1\n",
    "dt = T / M\n",
    "mid = BrownianMidprice(s0, sigma, num_traj=N, dt=dt, T=T, seed=SEED)\n",
    "arr = PoissonArrivals(A, A, num_traj=N, dt=dt, T=T, seed=SEED)\n",
    "dyn = LimitOrderDynamics(mid, arr, fill_k=k_fill, max_depth=20.0)\n",
    "\n",
    "# Single-trajectory plotting (RL-style)\n",
    "env = TradingEnv(dynamics=dyn, T=T, M=M, seed=SEED, return_vectorized=False)\n",
    "agent_inf = AvellanedaStoikovAgent(env, gamma=0.8, mode=\"infinite\", q_max=5)\n",
    "plot_trajectory(env, agent_inf, show_reservation=False)\n",
    "\n",
    "# Batch stats & PnL hist (vectorized episode)\n",
    "mid = BrownianMidprice(s0, sigma, num_traj=512, dt=dt, T=T, seed=SEED)\n",
    "arr = PoissonArrivals(A, A, num_traj=512, dt=dt, T=T, seed=SEED)\n",
    "dyn = LimitOrderDynamics(mid, arr, fill_k=k_fill, max_depth=20.0)\n",
    "env_vec = TradingEnv(dynamics=dyn, T=T, M=M, seed=SEED, return_vectorized=True)\n",
    "agent_inf = AvellanedaStoikovAgent(env_vec, gamma=0.8, mode=\"infinite\", q_max=5)\n",
    "results, fig, totals = generate_results_table_and_hist(env_vec, agent_inf)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd90bc7",
   "metadata": {},
   "source": [
    "Hawkes distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01391933",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED, T, M, s0, sigma, A, k_fill, N = 42, 1.0, 200, 100.0, 2.0, 140.0, 1.5, 1\n",
    "dt = T / M\n",
    "mu, kappa, jump = hawkes_params(dt=dt, p_target=0.30, eta=0.85, memory_steps=10)\n",
    "\n",
    "mid = BrownianMidprice(s0, sigma, num_traj=N, dt=dt, T=T, seed=SEED)\n",
    "arr = HawkesArrivals(A, A, num_traj=N, dt=dt, T=T, seed=SEED, kappa=kappa, jump=jump)\n",
    "dyn = LimitOrderDynamics(mid, arr, fill_k=k_fill, max_depth=20.0)\n",
    "\n",
    "# Single-trajectory plotting (RL-style)\n",
    "env = TradingEnv(dynamics=dyn, T=T, M=M, seed=SEED, return_vectorized=False)\n",
    "agent = AvellanedaStoikovAgent(env, gamma=0.1)\n",
    "plot_trajectory(env, agent, show_reservation=False)\n",
    "\n",
    "# Batch stats & PnL hist (vectorized episode)\n",
    "mid = BrownianMidprice(s0, sigma, num_traj=512, dt=dt, T=T, seed=SEED)\n",
    "arr = HawkesArrivals(A, A, num_traj=N, dt=dt, T=T, kappa=kappa, jump=jump, seed=SEED)\n",
    "dyn = LimitOrderDynamics(mid, arr, fill_k=k_fill, max_depth=20.0)\n",
    "env_vec = TradingEnv(dynamics=dyn, T=T, M=M, seed=SEED, return_vectorized=True)\n",
    "agent = AvellanedaStoikovAgent(env_vec, gamma=0.1)\n",
    "results, fig, totals = generate_results_table_and_hist(env_vec, agent)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058184f",
   "metadata": {},
   "source": [
    "GLFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f05591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED, T, M, s0, sigma, A, k_fill, N, k = 42, 1.0, 200, 100.0, 2.0, 140.0, 1.5, 1, 0.5\n",
    "dt = T / M\n",
    "mid = BrownianMidprice(s0, sigma, num_traj=N, dt=dt, T=T, seed=SEED)\n",
    "arr = PoissonArrivals(A, A, num_traj=N, dt=dt, T=T, seed=SEED)\n",
    "dyn = LimitOrderDynamics(mid, arr, fill_k=k_fill, max_depth=20.0)\n",
    "    \n",
    "# Single-trajectory plotting (RL-style)\n",
    "env = TradingEnv(dynamics=dyn, T=T, M=M, seed=SEED, return_vectorized=False)\n",
    "agent = GLFTAgent(env, gamma=0.1, A=A, k=k, xi=1.0, tick=1.0)\n",
    "plot_trajectory(env, agent, show_reservation=False)\n",
    "\n",
    "# Batch stats & PnL hist (vectorized episode)\n",
    "mid = BrownianMidprice(s0, sigma, num_traj=512, dt=dt, T=T, seed=SEED)\n",
    "arr = PoissonArrivals(A, A, num_traj=512, dt=dt, T=T, seed=SEED)\n",
    "dyn = LimitOrderDynamics(mid, arr, fill_k=k_fill, max_depth=20.0)\n",
    "env_vec = TradingEnv(dynamics=dyn, T=T, M=M, seed=SEED, return_vectorized=True)\n",
    "GLFT_agent = GLFTAgent(env, gamma=0.1, A=A, k=k, xi=1.0, tick=1.0)\n",
    "results, fig, totals = generate_results_table_and_hist(env_vec, GLFT_agent)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05e3d64",
   "metadata": {},
   "source": [
    "Plotting difference between Poisson distribution and Hawkes distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd751e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_poisson_vs_hawkes(dt=0.01, steps=200, seed=42,\n",
    "                          lam_buy=30, lam_sell=30,\n",
    "                          mu=10, kappa=60, jump=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b3a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto-import path or pass your classes explicitly\n",
    "from stochastic_proc.arrivals import PoissonArrivals, HawkesArrivals\n",
    "\n",
    "compare_poisson_vs_hawkes(\n",
    "    dt=0.01, steps=200, seed=42,\n",
    "    lam_buy=30, lam_sell=30,\n",
    "    mu=10, kappa=60, jump=40,\n",
    "    poisson_cls=PoissonArrivals,\n",
    "    hawkes_cls=HawkesArrivals,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd70ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from stochastic_proc.arrivals import PoissonArrivals, HawkesArrivals\n",
    "print(\"PoissonArrivals:\", inspect.signature(PoissonArrivals.__init__))\n",
    "print(\"HawkesArrivals :\", inspect.signature(HawkesArrivals.__init__))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mysimenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
